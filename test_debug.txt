Namespace(inputs=['checkpoints/multi30k-en2de//-'], output='checkpoints/multi30k-en2de//-/last10.ensemble.pt', num_epoch_checkpoints=10, num_update_checkpoints=None, checkpoint_upper_bound=None)
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt

fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
multi30k-en2de
multi30k-en2de==multi30k-en2de
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
multi30k-en2de
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/ -s en -t --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path --image-feat-dim --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
de
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-06 23:52:24 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-06 23:52:24 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-06 23:52:24 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-06 23:52:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test.en-de.en
2022-07-06 23:52:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test.en-de.de
2022-07-06 23:52:25 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test en-de 1000 examples
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-06 23:57:00 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-06 23:57:00 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-06 23:57:00 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-06 23:57:00 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-06 23:57:01 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-06 23:57:01 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-06 23:57:01 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-06 23:57:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-06 23:57:24 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 2.9s (348.41 sentences/s, 4366.30 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:02:21 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:02:21 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:02:21 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:02:21 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:02:21 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:02:21 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:02:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:03:00 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:03:00 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 6.6s (150.93 sentences/s, 1891.45 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:06:41 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:06:41 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:06:41 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:06:41 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:06:41 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:06:41 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:06:41 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:07:10 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:07:10 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 8.9s (111.88 sentences/s, 1402.05 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:13:26 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:13:26 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:13:26 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:13:26 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:13:26 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:13:26 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:13:26 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:14:12 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:14:12 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 9.2s (108.73 sentences/s, 1362.65 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:19:25 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:19:25 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:19:25 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:19:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:19:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:19:25 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:19:25 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:20:03 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:20:03 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 18.7s (53.60 sentences/s, 671.67 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:25:25 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:25:25 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:25:25 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:25:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:25:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:25:25 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:25:25 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:26:00 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:26:00 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 5.7s (176.89 sentences/s, 2216.75 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:32:08 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:32:08 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:32:08 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:32:08 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:32:08 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:32:08 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:32:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:33:11 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:33:11 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 9.7s (103.18 sentences/s, 1293.06 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:41:50 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:41:50 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:41:50 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:41:50 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:41:50 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:41:50 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:41:50 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:42:08 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:42:08 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 4.2s (240.45 sentences/s, 3013.35 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:49:01 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:49:01 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:49:01 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:49:01 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:49:01 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:49:01 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:49:01 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:49:35 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:49:35 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 14.0s (71.60 sentences/s, 897.26 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:53:16 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:53:16 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:53:16 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:53:16 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:53:16 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:53:16 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:53:16 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:53:49 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:53:49 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 6.9s (144.05 sentences/s, 1805.25 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:55:08 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:55:08 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:55:08 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:55:08 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:55:08 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:55:08 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:55:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:55:45 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:55:45 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 3.0s (335.68 sentences/s, 4206.71 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 00:59:31 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 00:59:32 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 00:59:32 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 00:59:32 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 00:59:32 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 00:59:32 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 00:59:32 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 00:59:47 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 00:59:47 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 2.5s (403.30 sentences/s, 5054.10 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:02:21 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:02:21 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:02:21 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:02:21 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:02:21 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:02:21 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:02:21 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:03:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:03:24 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 20.0s (50.11 sentences/s, 628.00 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:09:32 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:09:32 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:09:32 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:09:32 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:09:32 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:09:32 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:09:32 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:10:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:10:29 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 12.3s (81.12 sentences/s, 1016.60 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:14:01 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:14:01 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:14:01 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:14:01 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:14:01 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:14:01 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:14:01 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:14:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:14:38 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 7.7s (130.16 sentences/s, 1631.15 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:18:25 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:18:25 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:18:25 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:18:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:18:25 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:18:25 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:18:25 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:18:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:18:58 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 11.8s (84.67 sentences/s, 1061.15 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:22:30 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:22:30 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:22:30 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:22:30 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:22:30 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:22:30 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:22:30 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:23:15 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:23:15 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 10.7s (93.73 sentences/s, 1174.60 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
VizSeqScore(corpus_score=0.02, sent_scores=None, group_scores=None)
color
restrict:
219/381=57.48
relaxed:
339/381=88.98
people
restrict:
371/403=92.06
relaxed:
394/403=97.77
fairseq-generate data-bin/multi30k.en-de -s en -t de --path checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt --gen-subset test1 --batch-size 128 --beam 5 --lenpen 0.8 --quiet --remove-bpe --task image_mmt --image-feat-path data/vit_base_patch16_384 --image-feat-dim 768 --output checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt
2022-07-07 01:39:04 | INFO | fairseq_cli.generate | Namespace(no_progress_bar=False, log_interval=100, log_format=None, tensorboard_logdir=None, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, checkpoint_suffix='', checkpoint_shard_count=1, quantization_config_path=None, profile=False, criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='image_mmt', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=None, batch_size=128, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=None, batch_size_valid=128, curriculum=0, gen_subset='test1', num_shards=1, shard_id=0, distributed_world_size=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, fast_stat_sync=False, broadcast_buffers=False, distributed_wrapper='DDP', slowmo_momentum=None, slowmo_algorithm='LocalSGD', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', path='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt', remove_bpe='@@ ', quiet=True, model_overrides='{}', results_path=None, beam=5, nbest=1, max_len_a=0, max_len_b=200, min_len=1, match_source_len=False, no_early_stop=False, unnormalized=False, no_beamable_mm=False, lenpen=0.8, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=False, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, output='checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/hypo.txt', random_image_translation=False, force_anneal=None, lr_shrink=0.1, warmup_updates=0, data='data-bin/multi30k.en-de', source_lang='en', target_lang='de', load_alignments=False, left_pad_source='True', left_pad_target='False', max_source_positions=1024, max_target_positions=1024, upsample_primary=1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_args=None, eval_bleu_print_samples=False, image_feat_path=['data/vit_base_patch16_384'], image_feat_dim=[768], no_seed_provided=False)
2022-07-07 01:39:04 | INFO | fairseq.tasks.image_multimodal_translation | [en] dictionary: 9712 types
2022-07-07 01:39:04 | INFO | fairseq.tasks.image_multimodal_translation | [de] dictionary: 9712 types
2022-07-07 01:39:04 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.en
2022-07-07 01:39:04 | INFO | fairseq.data.data_utils | loaded 1000 examples from: data-bin/multi30k.en-de/test1.en-de.de
2022-07-07 01:39:04 | INFO | fairseq.tasks.image_multimodal_translation | data-bin/multi30k.en-de test1 en-de 1000 examples
2022-07-07 01:39:04 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/multi30k-en2de/vit_base_patch16_384/vit_base_patch16_384-mask0/last10.ensemble.pt
2022-07-07 01:40:00 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2
2022-07-07 01:40:00 | INFO | fairseq_cli.generate | Translated 1000 sentences (12532 tokens) in 22.6s (44.32 sentences/s, 555.46 tokens/s)
Generate test1 with beam=5: BLEU4 = 31.50, 64.2/38.4/24.6/16.2 (BP=1.000, ratio=1.001, syslen=10768, reflen=10759)
VizSeqScore(corpus_score=0.02, sent_scores=None, group_scores=None)
color
restrict:
219/381=57.48
relaxed:
339/381=88.98
people
restrict:
371/403=92.06
relaxed:
394/403=97.77
